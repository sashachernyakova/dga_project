# dga_project

## Задание:
Разработать систему машинного обучения, которая по написанию домена предсказывает, является ли этот домен DGA – доменом, созданным алгоритмом. Сгенерированные домены используются авторами malware для управления зараженными компьютерами (они не могут зарегистрировать и пользовать один домен т.к. этот домен заблокируют, так что malware в зависимости от даты обращается на определенный сгенерированный домен, который автор регистрирует чтобы управлять компьютерами в эту дату).


Для выполнения задания предоставляются две выборки: валидационная (val.csv) и проверочная (test.csv). Выборки представлены в виде csv файлов с колонкой domain - сам домен, и для валидационной – is_dga – сгенерирован ли этот домен: 1=да, 0=нет. На валидационной выборке требуется подсчитать характеристики точности и записать в текстовый файл validation.txt со следующим содержанием: True positive, False positive, False negative, True negative,  Accuracy, Precision, Recall, F1. Для проверочной выборки требуется создать файл prediction.csv, с двумя колонками – domain и is_dga, в котором для каждого домена проверочной выборки, в том же порядке, будет содержаться предсказание.

## Решение:
words.txt и legit_100k.txt - словари для построения символьных NGrams.

train.py - выполняет обучение и записывает модель в файл (dga_model.pkl). 

validate.py - читает модель из файла и создает файл validation.txt. 

predict.py - читает модель из файла и создает файл prediction.csv.

Каждый из трех запускается без аргументов командной строки.

generate_features.py - генерирует признаки для различных наблюдений.


requirements.txt - необходимые библиотеки для запуска проекта.


Для обучения использовался свой датасет. 

В качестве обучающей выборки был взят топ-миллион от alexa (белые домены) и dga домены с сайта kaggle (зловредные домены). Данные были взяты из открытых источников. В отдельном парсере обработаны и предоставлены сюда уже как train.csv.

train2.csv - 19500 белых доменов и 19500 зловредных доменов. Данная выборка сбалансирована и при обучении модели на ней validation.txt выглядел так:

True positive: 3944

False positive: 725

False negative: 1074

True negative: 4257

Accuracy: 0.8201

Precision: 0.8447

Recall: 0.7860

F1: 0.8143

AUC: 0.8961


В качестве классификатора был выбран Случайный лес (были рассмотрены и другие, но данный классификатор показал наилучшие метрики и AUC). Анализируя AUC, классификатор отличный. Однако в данной задаче намного важнее не называть белые домены зловредными, чем зловредные не называть белыми, то есть нужно стремиться понизить FP. Для этого было решено использовать выборку train.csv - 19500 dga и 60000 белых доменов. Данная выборка не сбалансирована, то есть модель в непонятных ситуациях чаще будет предсказывать домен как белый, а не dga. Таким образом удалось уменьшить FP почти в 2 раза. 


Как можно улучшить показатели:
1) добавить в train.csv больше белых доменов, но несбалансированность будет большая, что не есть хорошо
2) рассмотреть больше белых доменов (в открытом источнике 1 миллион) и больше dga доменов (в открытом источнике 600000), но тогда будет сильно дольше анализ
3) найти более подходящие словари words.txt и legit_100k.txt. При построении символьных NGrams были рассмотрены слова из этих словарей (взяты из открытых источников), они далеко не идеальны.
4) возможно модифицировать признаки или добавить новые, хотя на мой взгляд, признаков тут более чем достаточно.

## Запуск скриптов:
python train.py

python validate.py

python predict.py
