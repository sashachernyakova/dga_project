# dga_project

В качестве обучающей выборки был взят топ-миллион от alexa (белые домены) и dga домены 
с сайта kaggle (зловредные домены). Данные были взяты из открытых источников. В 
отдельном парсере обработаны и предоставлены сюда уже как train.csv.
train2.csv - 19500 белых доменов и 19500 зловредных доменов. Данная выборка 
сбалансирована и при обучении модели на ней validation.txt выглядел так:
True positive: 3944
False positive: 725
False negative: 1074
True negative: 4257
Accuracy: 0.8201
Precision: 0.8447
Recall: 0.7860
F1: 0.8143
AUC: 0.8961

В качестве классификатора был выбран Случайный лес (были рассмотрены и другие, но 
данный классификатор показал наилучшие метрики и AUC). Анализируя AUC, классификатор 
отличный. Однако в данной задаче намного важнее не называть белые домены зловредными, 
чем зловредные не называть белыми, то есть нужно стремиться понизить FP. 
Для этого было решено использовать выборку train.csv - 19500 dga и 60000 белых доменов. Данная выборка не сбалансирована, то есть модель в непонятных 
ситуациях чаще будет предсказывать домен как белый, а не dga. Таким образом удалось 
уменьшить FP почти в 2 раза. 

Как можно улучшить показатели:
1) добавить в train.csv больше белых доменов, но несбалансированность будет большая, 
что не есть хорошо
2) рассмотреть больше белых доменов (в открытом источнике 1 миллион) и больше dga 
доменов (в открытом источнике 600000), но тогда будет сильно дольше анализ
3) найти более подходящие словари words.txt и legit_100k.txt. При построении 
символьных NGrams были рассмотрены слова из этих словарей (взяты из открытых 
источников), они далеко не идеальны.
4) возможно модифицировать признаки или добавить новые, хотя на мой взгляд, признаков 
тут более чем достаточно.

